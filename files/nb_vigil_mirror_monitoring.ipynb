{"cells":[{"cell_type":"markdown","source":["# Fabric Notebook: Monitor ALL Mirrored Database Tables\n","\n","#### Monitors all tables in ALL mirrored databases in the workspace and FAILS the notebook if any are unhealthy.\n","\n","#### Prerequisites:\n","- Notebook identity needs MirroredDatabase.Read.All or Item.Read.All"],"metadata":{},"id":"b191554b-5a51-453a-9557-d967ee36e64b"},{"cell_type":"markdown","source":["## IMPORTS & CONSTANTS"],"metadata":{},"id":"e34f1d20-923b-4b6e-9409-ec545be4599a"},{"cell_type":"code","source":["import notebookutils\n","import requests\n","from datetime import datetime\n","from typing import Optional\n","\n","# ------------------------------------------------------------------------------\n","# Statuses that indicate healthy replication\n","# Add/remove statuses as needed based on Fabric API documentation\n","# ------------------------------------------------------------------------------\n","HEALTHY_STATUSES = [\"Replicating\", \"Running\", \"Succeeded\"]"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"fa6b9aaf-bb3f-4784-8f17-4fea8f61910c"},{"cell_type":"markdown","source":["## CONFIGURATION"],"metadata":{},"id":"003b6502-fbf1-499b-851a-23853b0e4615"},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Get workspace context from notebookutils (no Spark session required)\n","# ------------------------------------------------------------------------------\n","RUNTIME_CONTEXT = notebookutils.runtime.context\n","\n","WORKSPACE_ID = RUNTIME_CONTEXT.get(\"workspaceId\") or RUNTIME_CONTEXT.get(\"currentWorkspaceId\")\n","WORKSPACE_NAME = RUNTIME_CONTEXT.get(\"workspaceName\") or RUNTIME_CONTEXT.get(\"currentWorkspaceName\") or \"Unknown\"\n","\n","if not WORKSPACE_ID:\n","    raise Exception(\"Could not determine workspace ID from notebookutils.runtime.context\")\n","\n","# OneLake path root for this workspace\n","ONELAKE_WORKSPACE_ROOT = f\"abfss://{WORKSPACE_ID}@onelake.dfs.fabric.microsoft.com/\"\n","\n","print(f\"Workspace ID:   {WORKSPACE_ID}\")\n","print(f\"Workspace Name: {WORKSPACE_NAME}\")\n","print(f\"OneLake Root:   {ONELAKE_WORKSPACE_ROOT}\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"c01e6521-230b-41e3-961c-4d7fd293b447"},{"cell_type":"markdown","source":["## HELPER FUNCTIONS"],"metadata":{},"id":"d0af1787-fb04-443d-a0bc-d244679bce88"},{"cell_type":"code","source":["def get_fabric_token() -> str:\n","    \"\"\"\n","    Retrieve OAuth token for Fabric API calls.\n","    \"\"\"\n","    return notebookutils.credentials.getToken(\"https://api.fabric.microsoft.com\")\n","\n","\n","def get_all_mirrored_databases(workspace_id: str) -> list[dict]:\n","    \"\"\"\n","    Returns ALL MirroredDatabase items in the workspace.\n","    \n","    Each item has: { \"id\": \"...\", \"displayName\": \"...\", \"type\": \"MirroredDatabase\", ... }\n","    \n","    Returns empty list if none found.\n","    \"\"\"\n","    token = get_fabric_token()\n","    url = f\"https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}/items\"\n","\n","    response = requests.get(url, headers={\"Authorization\": f\"Bearer {token}\"})\n","    response.raise_for_status()\n","\n","    # Filter to only MirroredDatabase items\n","    mirrors = [\n","        item for item in response.json().get(\"value\", [])\n","        if item.get(\"type\") == \"MirroredDatabase\"\n","    ]\n","\n","    return mirrors"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"36581978-ee4d-4753-b811-d23fe3d99212"},{"cell_type":"code","source":["def resolve_mirror_tables_path(\n","    onelake_workspace_root: str,\n","    mirrored_db_id: str,\n","    mirrored_db_name: str\n",") -> Optional[str]:\n","    \"\"\"\n","    Attempts to resolve the Tables folder path for a mirrored database.\n","    \n","    Fabric may use either the item ID or the display name with suffix.\n","    \n","    Returns the resolved path, or None if neither candidate exists.\n","    \"\"\"\n","    candidates = [\n","        f\"{onelake_workspace_root}{mirrored_db_id}/Tables\",\n","        f\"{onelake_workspace_root}{mirrored_db_name}.MountedRelationalDatabase/Tables\",\n","    ]\n","\n","    for path in candidates:\n","        try:\n","            notebookutils.fs.ls(path)\n","            return path\n","        except Exception:\n","            pass\n","\n","    return None\n","\n","\n","def discover_tables_in_mirror(tables_root_path: str) -> list[str]:\n","    \"\"\"\n","    Discovers all tables under the mirrored database Tables folder.\n","    \n","    Expects structure: Tables/{schema}/{table_name}/\n","    \n","    Returns list of 'schema.table' strings.\n","    \"\"\"\n","    tables = []\n","\n","    # Iterate schemas (top-level folders under Tables)\n","    for schema_item in notebookutils.fs.ls(tables_root_path):\n","        if schema_item.isDir:\n","            schema_name = schema_item.name\n","            schema_path = f\"{tables_root_path}/{schema_name}\"\n","\n","            # Iterate tables within each schema\n","            for table_item in notebookutils.fs.ls(schema_path):\n","                if table_item.isDir:\n","                    tables.append(f\"{schema_name}.{table_item.name}\")\n","\n","    return tables"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"f534298d-f304-4fce-bfc8-2cd46aa5e18f"},{"cell_type":"code","source":["def get_tables_mirroring_status(workspace_id: str, mirrored_db_id: str) -> dict:\n","    \"\"\"\n","    Call the Get Tables Mirroring Status API for a specific mirrored database.\n","    \n","    Returns dict keyed by 'schema.table' (lowercase) for easy lookup.\n","    \"\"\"\n","    token = get_fabric_token()\n","    \n","    url = (\n","        f\"https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}\"\n","        f\"/mirroredDatabases/{mirrored_db_id}/getTablesMirroringStatus\"\n","    )\n","    \n","    response = requests.post(url, headers={\"Authorization\": f\"Bearer {token}\"})\n","    response.raise_for_status()\n","    \n","    # Build lookup dict keyed by schema.table (lowercase)\n","    result = {}\n","    for table in response.json().get(\"data\", []):\n","        schema = table.get(\"sourceSchemaName\", \"\")\n","        name = table.get(\"sourceTableName\", \"\")\n","        key = f\"{schema}.{name}\".lower()\n","        result[key] = {\n","            \"schema\": schema,\n","            \"table\": name,\n","            \"status\": table.get(\"status\", \"Unknown\"),\n","            \"metrics\": table.get(\"metrics\", {}),\n","            \"error_message\": table.get(\"errorMessage\")\n","        }\n","    \n","    return result"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"3b030b5e-8b6f-4fd2-a070-523de5bd0470"},{"cell_type":"code","source":["def check_tables(\n","    tables_to_monitor: list[str],\n","    status_lookup: dict,\n","    healthy_statuses: list[str]\n",") -> tuple[list[dict], list[dict]]:\n","    \"\"\"\n","    Check each table in the monitor list against the API response.\n","    \n","    Returns: (healthy_tables, failed_tables)\n","        - healthy_tables: list of dicts with table info\n","        - failed_tables: list of dicts with table info and failure reason\n","    \"\"\"\n","    healthy = []\n","    failed = []\n","    \n","    for table_spec in tables_to_monitor:\n","        key = table_spec.lower().strip()\n","        \n","        # Table not found in mirroring response\n","        if key not in status_lookup:\n","            failed.append({\n","                \"table\": table_spec,\n","                \"status\": \"NOT_FOUND\",\n","                \"reason\": \"Table not found in mirroring status - may be removed or mirroring stopped\",\n","                \"last_sync\": None\n","            })\n","            continue\n","        \n","        info = status_lookup[key]\n","        status = info[\"status\"]\n","        metrics = info[\"metrics\"]\n","        last_sync = metrics.get(\"lastSyncDateTime\", \"N/A\")\n","        \n","        if status in healthy_statuses:\n","            healthy.append({\n","                \"table\": table_spec,\n","                \"status\": status,\n","                \"last_sync\": last_sync,\n","                \"processed_rows\": metrics.get(\"processedRows\", 0)\n","            })\n","        else:\n","            failed.append({\n","                \"table\": table_spec,\n","                \"status\": status,\n","                \"reason\": info.get(\"error_message\") or f\"Status '{status}' not in healthy list\",\n","                \"last_sync\": last_sync\n","            })\n","    \n","    return healthy, failed"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"8ce09237-d859-4442-8e45-1c819b0b20e6"},{"cell_type":"code","source":["def print_db_summary(db_name: str, healthy: list[dict], failed: list[dict]) -> None:\n","    \"\"\"\n","    Print a formatted summary for a single mirrored database.\n","    \"\"\"\n","    print(f\"\\n{'─' * 60}\")\n","    print(f\"Mirrored DB: {db_name}\")\n","    print(f\"{'─' * 60}\")\n","    \n","    # Healthy tables\n","    print(f\"\\n  ✅ HEALTHY ({len(healthy)}):\")\n","    if healthy:\n","        for t in healthy:\n","            print(f\"     {t['table']:<40} {t['status']:<15} Last sync: {t['last_sync']}\")\n","    else:\n","        print(\"     (none)\")\n","    \n","    # Failed tables\n","    print(f\"\\n  ❌ FAILED ({len(failed)}):\")\n","    if failed:\n","        for t in failed:\n","            print(f\"     {t['table']:<40} {t['status']:<15}\")\n","            print(f\"        Reason: {t['reason']}\")\n","            if t['last_sync']:\n","                print(f\"        Last sync: {t['last_sync']}\")\n","    else:\n","        print(\"     (none)\")\n","\n","\n","def print_final_summary(\n","    total_dbs: int,\n","    total_healthy: int,\n","    total_failed: int,\n","    all_failures: list[dict]\n",") -> None:\n","    \"\"\"\n","    Print the final aggregated summary across all mirrored databases.\n","    \"\"\"\n","    print(\"\\n\" + \"=\" * 60)\n","    print(f\"FINAL SUMMARY - {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\")\n","    print(\"=\" * 60)\n","    print(f\"Mirrored Databases Checked: {total_dbs}\")\n","    print(f\"Total Healthy Tables:       {total_healthy}\")\n","    print(f\"Total Failed Tables:        {total_failed}\")\n","    print(\"=\" * 60)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"0bc0d8aa-631f-460b-9e3e-da12ce343b3c"},{"cell_type":"markdown","source":["## MAIN EXECUTION"],"metadata":{},"id":"8a58a660-c1e7-434a-ad36-482d7e6fe089"},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Step 1: Discover all mirrored databases in the workspace\n","# ------------------------------------------------------------------------------\n","mirrored_databases = get_all_mirrored_databases(WORKSPACE_ID)\n","\n","if not mirrored_databases:\n","    print(\"⚠️  No mirrored databases found in this workspace. Nothing to monitor.\")\n","else:\n","    print(f\"Found {len(mirrored_databases)} mirrored database(s) in workspace '{WORKSPACE_NAME}':\")\n","    for db in mirrored_databases:\n","        print(f\"  - {db['displayName']} ({db['id']})\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"58382f7f-f367-4360-92c8-697caf231a70"},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Step 2: Iterate over each mirrored database, check table health\n","# ------------------------------------------------------------------------------\n","all_failures = []       # Accumulate failures across all DBs: {\"db_name\": ..., \"table\": ..., ...}\n","total_healthy_count = 0\n","total_failed_count = 0\n","dbs_processed = 0\n","\n","for mirror_item in mirrored_databases:\n","    db_id = mirror_item[\"id\"]\n","    db_name = mirror_item[\"displayName\"]\n","    \n","    print(f\"\\n{'=' * 60}\")\n","    print(f\"Processing: {db_name}\")\n","    print(f\"{'=' * 60}\")\n","    \n","    # 2a: Resolve the Tables folder path\n","    tables_root_path = resolve_mirror_tables_path(ONELAKE_WORKSPACE_ROOT, db_id, db_name)\n","    \n","    if tables_root_path is None:\n","        print(f\"  ⚠️  Could not resolve Tables path for '{db_name}'. Skipping.\")\n","        # Optionally treat this as a failure\n","        all_failures.append({\n","            \"db_name\": db_name,\n","            \"db_id\": db_id,\n","            \"table\": \"(entire database)\",\n","            \"status\": \"PATH_NOT_FOUND\",\n","            \"reason\": \"Could not resolve Tables folder path in OneLake\"\n","        })\n","        total_failed_count += 1\n","        continue\n","    \n","    print(f\"  Tables path: {tables_root_path}\")\n","    \n","    # 2b: Discover all tables in this mirrored database\n","    tables_to_monitor = discover_tables_in_mirror(tables_root_path)\n","    \n","    if not tables_to_monitor:\n","        print(f\"  ⚠️  No tables discovered under '{db_name}'. Skipping.\")\n","        continue\n","    \n","    print(f\"  Discovered {len(tables_to_monitor)} tables.\")\n","    \n","    # 2c: Get mirroring status from API\n","    status_lookup = get_tables_mirroring_status(WORKSPACE_ID, db_id)\n","    print(f\"  API returned status for {len(status_lookup)} tables.\")\n","    \n","    # 2d: Check health of each table\n","    healthy_tables, failed_tables = check_tables(\n","        tables_to_monitor,\n","        status_lookup,\n","        HEALTHY_STATUSES\n","    )\n","    \n","    # 2e: Print per-DB summary\n","    print_db_summary(db_name, healthy_tables, failed_tables)\n","    \n","    # 2f: Accumulate results\n","    total_healthy_count += len(healthy_tables)\n","    total_failed_count += len(failed_tables)\n","    dbs_processed += 1\n","    \n","    # Tag failures with the DB name for final error message\n","    for f in failed_tables:\n","        all_failures.append({\n","            \"db_name\": db_name,\n","            \"db_id\": db_id,\n","            **f\n","        })"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"327060a2-6ca2-4827-a1ab-59cb8e4e4bea"},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Step 3: Print final summary and fail notebook if any tables are unhealthy\n","# ------------------------------------------------------------------------------\n","print_final_summary(dbs_processed, total_healthy_count, total_failed_count, all_failures)\n","\n","if all_failures:\n","    # Build detailed error message\n","    error_lines = [\n","        f\"Mirrored table replication failure detected!\",\n","        f\"\",\n","        f\"Failed tables ({len(all_failures)}):\"\n","    ]\n","    for f in all_failures:\n","        error_lines.append(f\"  - [{f['db_name']}] {f['table']}: {f['status']} - {f.get('reason', 'Unknown')}\")\n","    \n","    error_msg = \"\\n\".join(error_lines)\n","    \n","    # Raise exception to fail the notebook (and any calling pipeline)\n","    raise Exception(error_msg)\n","\n","print(\"\\n✅ All monitored tables across all mirrored databases are healthy - notebook completed successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"a89b6304-ce4b-4b6d-a8c1-d97ff3819725"}],"metadata":{"kernel_info":{"name":"jupyter","jupyter_kernel_name":"python3.11"},"kernelspec":{"name":"jupyter","display_name":"Jupyter"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"jupyter_python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}}},"nbformat":4,"nbformat_minor":5}